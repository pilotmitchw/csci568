<!--
	Needs:
	-Intro descr "association analysis" and typical model-building process (a priori, frequent itemset gen, rule generation, etc)
	

-->
<html>
    <head>
        <title>Association Analysis</title>
    </head>
    
    <body>
        <h1>Association Analysis</h1>
        <p>Association analysis is a data mining task that seeks to discover interesting relationships hidden in large datasets. These relationships are revealed in the form of association rules of sets of frequent items. This task is often used to find relationships in market basket and transaction data. Association analysis can be performed only on asymmetric binary data.</p>
        <p>Association analysis is performed in two major steps. The first is frequent itemset generation, in which all itemsets that meet a metric are found. The second uses the findings of the first to extract all high-confidence association rules.</p>
        <h2>Frequent itemset generation</h2>
        <p>Testing every combination of items in a transaction or market basket leads to an intractable problem, so frequent itemset generation seeks to reduce the number of possibilties the algorithm must take into consideration by applying a principle called the Apriori principle. This priniple states that an itemset that is frequent, all its subsets are also frequent. It is also true that all infrequent itemsets have infrequent supersets. Using these rules, the number of itemsets that must be taken into consideration is drastically reduced.</p>
        <p>After this pruning takes place, the itemsets are further processed by taking each 1-itemset (each itemset containing one object) and constructing their supersets. This is done by one of two methods, the F(K-1) X F(1) method or the F(K-1) X F(K-1) method. In the first method, each F(K-1) itemsets are combined with each of the 1-itemsets and their support (the number of times the itemset appears in the dataset) is calcuated. By the apriori principle, any supersets of any set determined to be infrequent (below a certain support threshold) are also infrequent. At the end of this process, the algorithm has the minimum number of itemsets to extract rules from.</p>
        <h2>Rule generation</h2>
        <p>Rules are generated by the association analysis algorithm in a level-wise approach where each level corresponds to the number of items that belong to the rule consequent. In the rule a => b, b is the consequent. Each rule is generated by increasing the number of items on the consequent side, then calculating the rule's confidence, or the number of times that the rule is correct in the dataset divided by the number of times that it can possibly be correct. This value of confidence is what determines 'good' rules from 'bad' ones.</p>
        <h2>Benefits and drawbacks of association analysis</h2>
        <p>Association analysis by the apriori algorithm is dependent on the number of items and the average transaction length. One problem that comes up in association analysis is the lack of a good way to pick the support threshold for the frequent itemset generation process. Picking a threshold too high may miss interesting relationships, but when the threshold is too low, the algorithm becomes more expensive to use and many spurious patterns may result.</p>
    </body>
</html>